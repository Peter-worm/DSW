{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sorted paths of snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/\"\n",
    "\n",
    "# Regular expression to match the file format\n",
    "pattern = re.compile(r\"nextbike_data_(\\d{8}_\\d{6})\")\n",
    "\n",
    "files_with_dates = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    match = pattern.match(filename)\n",
    "    if match:\n",
    "        date_str = match.group(1)\n",
    "        try:\n",
    "            file_datetime = datetime.strptime(date_str, \"%Y%m%d_%H%M%S\")\n",
    "            full_path = os.path.join(folder_path, filename)\n",
    "            files_with_dates.append((file_datetime, full_path))\n",
    "        except ValueError:\n",
    "            print(f\"Skipping file with invalid datetime: {filename}\")\n",
    "\n",
    "files_with_dates.sort()\n",
    "sorted_paths = [path for _, path in files_with_dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_station_data(data, idx):\n",
    "    stations = {}\n",
    "    city  = data[\"countries\"][idx][\"cities\"][0]\n",
    "    for place in city.get(\"places\", []):\n",
    "        stations[place[\"uid\"]] = {\n",
    "            \"name\": place[\"name\"],\n",
    "            \"lat\": place[\"lat\"],\n",
    "            \"lng\": place[\"lng\"],\n",
    "            \"bikes\": set(bike[\"number\"] for bike in place.get(\"bike_list\", []))\n",
    "        }\n",
    "    return stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        state = json.load(f)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timestamp_from_path(path):\n",
    "    filename = os.path.basename(path)\n",
    "    datetime_str = filename.replace(\"nextbike_data_\", \"\").replace(\".json\", \"\")\n",
    "    return datetime.strptime(datetime_str, \"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2city = {0: \"berlin\", 1: \"barcelona\", 2: \"innsbruck\", 3: \"warsaw\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop, only for one city (Berlin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: berlin\n",
      "1: barcelona\n",
      "2: innsbruck\n",
      "3: warsaw\n"
     ]
    }
   ],
   "source": [
    "for k,v in idx2city.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing city: berlin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 4284/15127 [16:27<38:38,  4.68it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250420_150400.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 8695/15127 [32:41<15:03,  7.12it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250423_210341.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 12288/15127 [46:28<07:17,  6.49it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250426_105401.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 14814/15127 [56:53<00:36,  8.52it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250429_062750.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15127/15127 [57:55<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing city: barcelona\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 4284/15127 [23:16<50:46,  3.56it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250420_150400.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 8694/15127 [46:03<10:11, 10.52it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250423_210341.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 12286/15127 [1:04:12<17:32,  2.70it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250426_105401.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 14812/15127 [1:16:52<01:20,  3.92it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250429_062750.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15127/15127 [1:19:08<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing city: innsbruck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 4284/15127 [18:36<23:07,  7.81it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250420_150400.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 8693/15127 [38:34<24:30,  4.37it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250423_210341.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 12288/15127 [53:42<06:24,  7.39it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250426_105401.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 14812/15127 [1:04:57<01:48,  2.91it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250429_062750.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15127/15127 [1:06:17<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing city: warsaw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 4284/15127 [18:47<35:10,  5.14it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250420_150400.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 8688/15127 [39:44<23:26,  4.58it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250423_210341.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 12286/15127 [57:16<14:08,  3.35it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250426_105401.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 14812/15127 [1:09:21<01:40,  3.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing path data/nextbike_data_20250429_062750.json: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15127/15127 [1:10:42<00:00,  3.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, city in idx2city.items():\n",
    "    print(f\"Processing city: {city}\")\n",
    "    save_path = f\"bike_movements_{city}.csv\"\n",
    "\n",
    "    bike_movements = []\n",
    "    disappeared_bikes = {}  # {bike_id: {\"from_station\": name, \"departure_time\": timestamp}}\n",
    "\n",
    "    previous_path = sorted_paths[0]\n",
    "    previous_state = extract_station_data(load_state(previous_path), idx)\n",
    "    previous_timestamp = extract_timestamp_from_path(previous_path)\n",
    "\n",
    "    for current_path in tqdm(sorted_paths[1:]):\n",
    "        try:\n",
    "            current_state = extract_station_data(load_state(current_path), idx)\n",
    "            current_timestamp = extract_timestamp_from_path(current_path)\n",
    "\n",
    "            # Check for disappeared bikes across all stations\n",
    "            for station_id, station_info in previous_state.items():\n",
    "                if station_id in current_state:\n",
    "                    current_bikes = current_state[station_id][\"bikes\"]\n",
    "                    disappeared = station_info[\"bikes\"] - current_bikes\n",
    "                    for bike in disappeared:\n",
    "                        if bike not in disappeared_bikes:\n",
    "                            disappeared_bikes[bike] = {\n",
    "                                \"from_station\": station_info[\"name\"],\n",
    "                                \"from_station_lat\": station_info[\"lat\"],\n",
    "                                \"from_station_lng\": station_info[\"lng\"],\n",
    "                                \"departure_time\": previous_timestamp\n",
    "                            }\n",
    "\n",
    "            # Try to locate disappeared bikes in the current state\n",
    "            bikes_found = []\n",
    "            for new_station_id, new_station_info in current_state.items():\n",
    "                if re.match(r\"^BIKE \\d+$\", new_station_info[\"name\"]): # We do not process temporary stations, those stattion are created when bike is rented but not returned, can be seen in bike_movements_old.ipynb \n",
    "                    continue\n",
    "                for bike in new_station_info[\"bikes\"]:\n",
    "                    if bike in disappeared_bikes:\n",
    "                        movement = {\n",
    "                            \"bike_id\": bike,\n",
    "                            \"from_station\": disappeared_bikes[bike][\"from_station\"],\n",
    "                            \"from_station_lat\": disappeared_bikes[bike][\"from_station_lat\"],\n",
    "                            \"from_station_lng\": disappeared_bikes[bike][\"from_station_lng\"],\n",
    "                            \"to_station\": new_station_info[\"name\"],\n",
    "                            \"to_station_lat\": new_station_info[\"lat\"],\n",
    "                            \"to_station_lng\": new_station_info[\"lng\"],\n",
    "                            \"departure_time\": disappeared_bikes[bike][\"departure_time\"],\n",
    "                            \"arrival_time\": current_timestamp\n",
    "                        }\n",
    "                        bike_movements.append(movement)\n",
    "                        # print(f\"Bike {bike} moved from {movement['from_station']} at {movement['departure_time']} \"\n",
    "                        #       f\"to {movement['to_station']} at {movement['arrival_time']}\")\n",
    "                        bikes_found.append(bike)\n",
    "\n",
    "            # Remove bikes we've found from the disappeared set\n",
    "            for bike in bikes_found:\n",
    "                del disappeared_bikes[bike]\n",
    "\n",
    "            previous_state = current_state\n",
    "            previous_timestamp = current_timestamp\n",
    "            # print(\"-\" * 20)\n",
    "            if len(bike_movements) > 1000:\n",
    "                new_data = pd.DataFrame(bike_movements)\n",
    "                new_data.to_csv(save_path, mode='a', header=not os.path.exists(save_path), index=False)\n",
    "                bike_movements = []\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing path {current_path}: {e}\")\n",
    "\n",
    "    # Save any remaining bike movements\n",
    "    new_data = pd.DataFrame(bike_movements)\n",
    "    new_data.to_csv(save_path, mode='a', header=not os.path.exists(save_path), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bike_movements_warsaw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "from_station\n",
       "Metro Centrum Nauki Kopernik        3352\n",
       "Arkadia                             2029\n",
       "Metro Dworzec Wileński - Targowa    1944\n",
       "Stefana Banacha - UW                1867\n",
       "Westfield Mokotów                   1707\n",
       "                                    ... \n",
       "AMB - METRO La Pau                    25\n",
       "AMB - Campus Diagonal - Besòs         16\n",
       "AMB - Diagonal II                      8\n",
       "AMB - METRO Baró de Viver              6\n",
       "AMB - Riera Blanca Nord                5\n",
       "Name: count, Length: 343, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"from_station\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movement count for each bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike 16204 moved 7 times\n",
      "Bike 100064 moved 5 times\n",
      "Bike 19155 moved 5 times\n",
      "Bike 16968 moved 5 times\n",
      "Bike 15180 moved 5 times\n",
      "Bike 10914 moved 5 times\n",
      "Bike 14425 moved 5 times\n",
      "Bike 17778 moved 5 times\n",
      "Bike 14328 moved 5 times\n",
      "Bike 19473 moved 5 times\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "bike_movement_counts = defaultdict(int)\n",
    "\n",
    "for movement in bike_movements:\n",
    "    bike_id = movement[\"bike_id\"]\n",
    "    bike_movement_counts[bike_id] += 1\n",
    "\n",
    "bike_movement_summary = sorted(bike_movement_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for bike_id, count in bike_movement_summary[:10]:\n",
    "    print(f\"Bike {bike_id} moved {count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movements for selected bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike 16204 departed from S+U Neukölln | BONUS-Station: Return(Rückgabe) here=15 mins free at 2025-04-02 20:32:34 and arrived at virtuell - Oderstraße/Siegfriedstraße at 2025-04-02 20:41:47\n",
      "Bike 16204 departed from virtuell - Oderstraße/Siegfriedstraße at 2025-04-02 21:01:18 and arrived at virtuell - Oderstraße/Siegfriedstraße at 2025-04-02 21:23:58\n",
      "Bike 16204 departed from virtuell - Oderstraße/Siegfriedstraße at 2025-04-02 21:43:29 and arrived at S Ostbahnhof | BONUS-Station: Return(Rückgabe) here=15 mins free at 2025-04-02 22:13:15\n",
      "Bike 16204 departed from S Ostbahnhof | BONUS-Station: Return(Rückgabe) here=15 mins free at 2025-04-02 22:34:50 and arrived at Köpenicker Straße/Eisenbahnstraße | BONUS-Station: Return(Rückgabe) here=15 mins free at 2025-04-02 22:42:02\n",
      "Bike 16204 departed from Köpenicker Straße/Eisenbahnstraße | BONUS-Station: Return(Rückgabe) here=15 mins free at 2025-04-03 01:10:14 and arrived at virtuell - Leipziger Straße/Jerusalemer Straße at 2025-04-03 01:30:49\n",
      "Bike 16204 departed from virtuell - Leipziger Straße/Jerusalemer Straße at 2025-04-03 01:56:31 and arrived at virtuell - Leipziger Straße/Markgrafenstraße at 2025-04-03 01:57:32\n",
      "Bike 16204 departed from virtuell - Leipziger Straße/Markgrafenstraße at 2025-04-03 02:00:37 and arrived at virtuell - Leipziger Straße/Jerusalemer Straße at 2025-04-03 02:01:39\n"
     ]
    }
   ],
   "source": [
    "target_bike_id = \"16204\"\n",
    "\n",
    "target_bike_movements = [\n",
    "    move for move in bike_movements if move[\"bike_id\"] == target_bike_id\n",
    "]\n",
    "\n",
    "for move in target_bike_movements:\n",
    "    print(\n",
    "        f\"Bike {move['bike_id']} departed from {move['from_station']} at {move['departure_time']} \"\n",
    "        f\"and arrived at {move['to_station']} at {move['arrival_time']}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
